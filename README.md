# ğŸ–¼ï¸ VisionSpeak  
### Attention-Based Image Captioning System (CNN + LSTM + Additive Attention)

<p align="center">
  <img src="glimpse.png" width="100%">
</p>

---

## ğŸ“Œ 1. Project Overview

**VisionSpeak** is a deep learningâ€“based image captioning system that generates natural language descriptions for images.

The system learns to:

- Extract spatial visual features from an image  
- Focus on different regions of the image while generating each word  
- Produce coherent captions using sequence modeling  
- Provide interpretable attention heatmaps  

### ğŸ¯ Core Objective

> Given an image â†’ Generate a grammatically meaningful caption describing the scene.

This project implements a classical **Encoderâ€“Decoder architecture with Attention**.

---

## ğŸ§  2. Key Concepts (Important Terms)

### ğŸ”¹ Convolutional Neural Network (CNN)

A **CNN** is a deep learning architecture designed for image understanding.

It extracts hierarchical spatial features using convolutional filters.

In this project:

- A pretrained CNN is used to extract image features.
- Each image is converted into a spatial feature map of shape:






